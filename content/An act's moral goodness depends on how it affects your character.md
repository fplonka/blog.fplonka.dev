---
date: 2025-02-15
---
Acts have obvious direct consequences. For example shouting at someone in public will make make the person you're shouting at upset. But they also have second-order consequences: by shouting at someone, you contribute to creating the sort of world where people shout at each other. You probably lower social trust, you probably make shouting in public a bit more acceptable. And you become the sort of person who shouts at people.

I think this last type of second-order consequence, where an act contributes very slightly to you becoming a different type of person, is under-appreciated and actually often dominates the moral calculus. And so it's actually quite useless to ask, for example, is it good to punch someone. If you're short-tempered and punch on angry an angry impulse, it's probably bad. If you're a bit of a coward and the punch is a step in the direction of you finally standing up for yourself, potentially it's good. 

![](images/file-20250215095306320.png "The tweet which inspired this post.")

On one hand this is a bit unsatisfying in that it means evaluating the moral goodness of an act is computationally intractable. But on the other, things do be like that sometimes. Some meandering thoughts related to this idea now follow.
## Blanket good-bad judgements are dumb
- not contextual enough
- but also they're doing some game theoretic coordination thing idk

## What kind of person does the act make you become?

Ok, so you punched someone. In what way does this change your character? What kind of person does this make you become? 

I think this question is slightly doomed, because your brain's black-box deep-learning machinery will do this unconsciously for you, and it will do it in a way which is probably not very amenable to neat interpretation. But attempting anyways, I think two things will be taken into account: the hypothesis's explanatory power and its simplicity. 

So if you punched Jack on Tuesday evening, your character changes such that you're the sort of person who punches Jack on Tuesday evenings. But it only moves in this direction a tiny bit because this hypothesis is so complicated and awkward, even though it explains your behavior quite well. Your character will probably also update somewhat in the direction of you being a generally violent person, since this is a decent explanation and also much simpler. But the exact real updates are some opaque black box neural-net mess, so you probably shouldn't think about this consciously too much. 

Mandatory predictive-processing digression: I don't mean 'character' and 'updates' abstractly and philosophically, I mean these to refer to real changes in your brain's real world-model. In the [predictive processing frame](https://slatestarcodex.com/2017/09/05/book-review-surfing-uncertainty/), somewhat speculatively, it makes sense to think of two 'you's: you, the bio-physical cellular automaton whose behavior is governed by physical law, and you, the self, the ego, i.e. your brain's model of what you-the-bio-automaton will do. The brain's world-model is of course part of the bio-automaton, and also your brain's world-model drives the bio-automaton's behavior. So when your world-model is predicting the bio-automaton it also has to predict what it itself will do, leading to some funny weird recursion business. I really like this idea and it deserves its own post at some point, but the relevant point for now is that in this frame, when you do something, this is useful evidence about what you-the-bio-automaton do: your brain will do some kind of approximate bayesian inference to update its own theory of how 'you' behave. This is e.g. how habits are implemented - you do something regularly, you-the-world-model make the inference that this is the sort of thing you-the-bio-automaton does, and the updated world-model drives the bio-automaton to behave this way even more in the future. The update after punching someone is analogous. 
## How this relates to Kant's murderer question

is universalizability some approximation of this inference thing?

But at a high-level, I think two 


## Does this have any practical takeaways at all or are we just playing word games?

in a way not very amenable to 


As is mandatory for this blog, to answer this question I must first plug the theory of predictive processing. Read [Scott's excellent post for crucial context](https://slatestarcodex.com/2017/09/05/book-review-surfing-uncertainty/). 




- hypotheses are favored based on simplicity and being good explanations
- doomed to think about this consciously, this is the domain of black box machine learnign bs

- as is mandatory for this blog, i must note that this fits in nicely with the predictive coding paradigm. your 'self' is a model of 

- on one hand this is cowardly because I can invoke this to judge things the way i want

- gradient descent, one feature will go up and down

- kolmogorov complexity again

As usual for my blog I need to plug predictive coding