---
date: 2025-02-15
---
Acts have obvious direct consequences. For example shouting at someone in public will make make the person you're shouting at upset. But they also have second-order consequences: by shouting at someone, you contribute to creating the sort of world where people shout at each other. You probably lower social trust, you probably make shouting in public a bit more acceptable. And you become the sort of person who shouts at people.

I think this last type of second-order consequence, where an act contributes very slightly to you becoming a different type of person, is under-appreciated and actually often dominates the moral calculus. And so it's actually quite useless to ask, for example, is it good to punch someone. If you're short-tempered and punch on angry an angry impulse, it's probably bad. If you're a bit of a coward and the punch is a step in the direction of you finally standing up for yourself, potentially it's good. 

![](images/file-20250215095306320.png "The tweet which inspired this thought.")

On one hand this is a bit unsatisfying in that it means evaluating the moral goodness of an act is computationally intractable. But on the other, things do be like that sometimes. Some meandering thoughts related to this idea now follow.

```
code example
```


## What kind of person exactly does the act make you become?
- hypotheses are biased by their simplicity


- on one hand this is cowardly because I can invoke this to judge things the way i want

- gradient descent, one feature will go up and down

- kolmogorov complexity again

As usual for my blog I need to plug predictive coding